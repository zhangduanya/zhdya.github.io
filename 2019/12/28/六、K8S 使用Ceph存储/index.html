<!DOCTYPE html>
<html lang="">





<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/apple-touch-icon.png">
  <link rel="icon" type="image/png" href="/img/favicon.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="description" content="Tough times never last, but tough people do.">
  <meta name="author" content="Zhdya">
  <meta name="keywords" content="">
  <title>六、K8S 使用Ceph存储 ~ 拼！就对了！</title>

  <link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
<link rel="stylesheet" href="/lib/bootstrap/css/bootstrap.min.css">
<link rel="stylesheet" href="/lib/mdbootstrap/css/mdb.min.css">
<link rel="stylesheet" href="/lib/github-markdown/github-markdown.min.css">
<link rel="stylesheet" href="//at.alicdn.com/t/font_1067060_qzomjdt8bmp.css">


  <link rel="stylesheet" href="/lib/prettify/tomorrow-night-eighties.min.css">

<link rel="stylesheet" href="/css/main.css">


  <link rel="stylesheet" href="/lib/fancybox/jquery.fancybox.min.css">


</head>


<body>
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">&nbsp;<strong>拼！就对了！</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/">ホーム</a>
          </li>
        
          
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/archives/">アーカイブ</a>
          </li>
        
          
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/categories/">カテゴリー</a>
          </li>
        
          
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/tags/">タグ</a>
          </li>
        
          
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/about/">本ブログ情報　</a>
          </li>
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;&nbsp;<i class="iconfont icon-search"></i>&nbsp;&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="view intro-2" id="background"
         style="background: url('/img/default.png')no-repeat center center;
           background-size: cover;
           background-attachment: fixed;">
      <div class="full-bg-img">
        <div class="mask rgba-black-light flex-center">
          <div class="container text-center white-text fadeInUp">
            <span class="h2" id="subtitle">
              
            </span>

            
              <br>
              
                <p class="mt-3">
                  <i class="fas fa-calendar-alt" aria-hidden="true"></i>&nbsp;
                  Saturday, December 28th 2019, 12:00 am
                </p>
              

              <p>
                
                  
                  &nbsp;<i class="far fa-chart-bar"></i>
                  <span class="post-count">
                    2.6k 字
                  </span>&nbsp;
                

                
                  
                  &nbsp;<i class="far fa-clock"></i>
                  <span class="post-count">
                      13 分钟
                  </span>&nbsp;
                

                
                  <!-- 不蒜子统计文章PV -->
                  
                  &nbsp;<i class="far fa-eye" aria-hidden="true"></i>&nbsp;
                  <span id="busuanzi_container_page_pv">
                    <span id="busuanzi_value_page_pv"></span> 次
                  </span>&nbsp;
                
              </p>
            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid">
  <div class="row">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-md">
      <div class="py-5 z-depth-3" id="board">
        <div class="post-content mx-auto" id="post">
          <div class="markdown-body">
            <h3 id="一、PV、PVC概述"><a href="#一、PV、PVC概述" class="headerlink" title="一、PV、PVC概述"></a>一、PV、PVC概述</h3><p>管理存储是管理计算的一个明显问题。PersistentVolume子系统为用户和管理员提供了一个API，用于抽象如何根据消费方式提供存储的详细信息。于是引入了两个新的API资源：PersistentVolume和PersistentVolumeClaim</p>
<blockquote>
<p>PersistentVolume（PV）是集群中已由管理员配置的一段网络存储。 集群中的资源就像一个节点是一个集群资源。 PV是诸如卷之类的卷插件，但是具有独立于使用PV的任何单个pod的生命周期。 该API对象包含存储的实现细节，即NFS，iSCSI或云提供商特定的存储系统。 </p>
</blockquote>
<blockquote>
<p>PersistentVolumeClaim（PVC）是用户存储的请求。 它类似于pod。Pod消耗节点资源，PVC消耗存储资源。 pod可以请求特定级别的资源（CPU和内存）。 权限要求可以请求特定的大小和访问模式。</p>
</blockquote>
<blockquote>
<p>虽然PersistentVolumeClaims允许用户使用抽象存储资源，但是常见的是，用户需要具有不同属性（如性能）的PersistentVolumes，用于不同的问题。 管理员需要能够提供多种不同于PersistentVolumes，而不仅仅是大小和访问模式，而不会使用户了解这些卷的实现细节。 对于这些需求，存在StorageClass资源。</p>
</blockquote>
<blockquote>
<p>StorageClass为集群提供了一种描述他们提供的存储的“类”的方法。 不同的类可能映射到服务质量级别，或备份策略，或者由群集管理员确定的任意策略。 Kubernetes本身对于什么类别代表是不言而喻的。 这个概念有时在其他存储系统中称为“配置文件”</p>
</blockquote>
<h3 id="二、POD动态供给"><a href="#二、POD动态供给" class="headerlink" title="二、POD动态供给"></a>二、POD动态供给</h3><blockquote>
<p>动态供给主要是能够自动帮你创建pv，需要多大的空间就创建多大的pv。k8s帮助创建pv，创建pvc就直接api调用存储类来寻找pv。</p>
</blockquote>
<blockquote>
<p>如果是存储静态供给的话，会需要我们手动去创建pv，如果没有足够的资源，找不到合适的pv，那么pod就会处于pending等待的状态。而动态供给主要的一个实现就是StorageClass存储对象，其实它就是声明你使用哪个存储，然后帮你去连接，再帮你去自动创建pv。</p>
</blockquote>
<h3 id="三、POD使用RBD做为持久数据卷"><a href="#三、POD使用RBD做为持久数据卷" class="headerlink" title="三、POD使用RBD做为持久数据卷"></a>三、POD使用RBD做为持久数据卷</h3><h4 id="3-1、安装与配置"><a href="#3-1、安装与配置" class="headerlink" title="3.1、安装与配置"></a>3.1、安装与配置</h4><p>RBD支持ReadWriteOnce，ReadOnlyMany两种模式</p>
<p>3.1.1、配置rbd-provisioner<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 如果使用kubeadm部署的集群需要这些额外的步骤 # 由于使用动态存储时 controller-manager 需要使用 rbd 命令创建 image # 所以 controller-manager 需要使用 rbd 命令 # 由于官方controller-manager镜像里没有rbd命令 # 如果没使用如下方式会报错无法成功创建pvc # 相关 issue https://github.com/kubernetes/kubernetes/issues/38923</span><br><span class="line"></span><br><span class="line">cat &gt;external-storage-rbd-provisioner.yaml&lt;&lt;EOF</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: rbd-provisioner</span><br><span class="line">  namespace: kube-system</span><br><span class="line">---</span><br><span class="line">kind: ClusterRole</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: rbd-provisioner</span><br><span class="line">rules:</span><br><span class="line">  - apiGroups: [&quot;&quot;]</span><br><span class="line">    resources: [&quot;persistentvolumes&quot;]</span><br><span class="line">    verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;, &quot;create&quot;, &quot;delete&quot;]</span><br><span class="line">  - apiGroups: [&quot;&quot;]</span><br><span class="line">    resources: [&quot;persistentvolumeclaims&quot;]</span><br><span class="line">    verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;, &quot;update&quot;]</span><br><span class="line">  - apiGroups: [&quot;storage.k8s.io&quot;]</span><br><span class="line">    resources: [&quot;storageclasses&quot;]</span><br><span class="line">    verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;]</span><br><span class="line">  - apiGroups: [&quot;&quot;]</span><br><span class="line">    resources: [&quot;events&quot;]</span><br><span class="line">    verbs: [&quot;create&quot;, &quot;update&quot;, &quot;patch&quot;]</span><br><span class="line">  - apiGroups: [&quot;&quot;]</span><br><span class="line">    resources: [&quot;endpoints&quot;]</span><br><span class="line">    verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;, &quot;create&quot;, &quot;update&quot;, &quot;patch&quot;]</span><br><span class="line">  - apiGroups: [&quot;&quot;]</span><br><span class="line">    resources: [&quot;services&quot;]</span><br><span class="line">    resourceNames: [&quot;kube-dns&quot;]</span><br><span class="line">    verbs: [&quot;list&quot;, &quot;get&quot;]</span><br><span class="line">---</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: rbd-provisioner</span><br><span class="line">subjects:</span><br><span class="line">  - kind: ServiceAccount</span><br><span class="line">    name: rbd-provisioner</span><br><span class="line">    namespace: kube-system</span><br><span class="line">roleRef:</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: rbd-provisioner</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: Role</span><br><span class="line">metadata:</span><br><span class="line">  name: rbd-provisioner</span><br><span class="line">  namespace: kube-system</span><br><span class="line">rules:</span><br><span class="line">- apiGroups: [&quot;&quot;]</span><br><span class="line">  resources: [&quot;secrets&quot;]</span><br><span class="line">  verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;, &quot;create&quot;, &quot;update&quot;, &quot;patch&quot;]</span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: RoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: rbd-provisioner</span><br><span class="line">  namespace: kube-system</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: Role</span><br><span class="line">  name: rbd-provisioner</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: rbd-provisioner</span><br><span class="line">  namespace: kube-system</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: rbd-provisioner</span><br><span class="line">  namespace: kube-system</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: rbd-provisioner</span><br><span class="line">  replicas: 1</span><br><span class="line">  strategy:</span><br><span class="line">    type: Recreate</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: rbd-provisioner</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: rbd-provisioner</span><br><span class="line">        image: &quot;quay.io/external_storage/rbd-provisioner:v2.0.0-k8s1.11&quot;</span><br><span class="line">        env:</span><br><span class="line">        - name: PROVISIONER_NAME</span><br><span class="line">          value: ceph.com/rbd</span><br><span class="line">      serviceAccount: rbd-provisioner</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"># kubectl apply -f external-storage-rbd-provisioner.yaml</span><br><span class="line"></span><br><span class="line"># 查看状态 等待running之后 再进行后续的操作</span><br><span class="line"># kubectl get pod -n kube-system</span><br></pre></td></tr></table></figure></p>
<p>3.1.2、配置storageclass<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1、创建pod时，kubelet需要使用rbd命令去检测和挂载pv对应的ceph image，所以要在所有的worker节点安装ceph客户端ceph-common。</span><br><span class="line">将ceph的ceph.client.admin.keyring和ceph.conf文件拷贝到master的/etc/ceph目录下</span><br><span class="line">yum -y install ceph-common</span><br><span class="line"></span><br><span class="line">如果K8S中是没有ceph客户端和配置文件，需要从ceph集群中copy下：</span><br><span class="line">scp /etc/ceph/ceph.c* root@192.168.171.11:/etc/ceph/</span><br><span class="line">scp /etc/ceph/ceph.c* root@192.168.171.12:/etc/ceph/</span><br><span class="line">scp /etc/ceph/ceph.c* root@192.168.171.13:/etc/ceph/</span><br><span class="line"></span><br><span class="line">这样就可以在K8S集群中查看集群的状态了！</span><br><span class="line"></span><br><span class="line">2、创建 osd pool 在ceph的mon或者admin节点</span><br><span class="line">ceph osd pool create kube 128 128 </span><br><span class="line">ceph osd pool ls</span><br><span class="line"></span><br><span class="line">3、创建k8s访问ceph的用户 在ceph的mon或者admin节点</span><br><span class="line">ceph auth get-or-create client.kube mon &apos;allow r&apos; osd &apos;allow class-read object_prefix rbd_children, allow rwx pool=kube&apos; -o ceph.client.kube.keyring</span><br><span class="line"></span><br><span class="line">4、查看key 在ceph的mon或者admin节点</span><br><span class="line">ceph auth get-key client.admin</span><br><span class="line">ceph auth get-key client.kube</span><br><span class="line"></span><br><span class="line">5、# 创建 admin secret # CEPH_ADMIN_SECRET 替换为 client.admin 获取到的key</span><br><span class="line">kubectl create secret generic ceph-secret --type=&quot;kubernetes.io/rbd&quot; \</span><br><span class="line">--from-literal=key=AQCeEwpeo+I8HRAAnBphr8lyGc6+JBT7jU7rgA== \</span><br><span class="line">--namespace=kube-system</span><br><span class="line"></span><br><span class="line">6、# 在 default 命名空间创建pvc用于访问ceph的 secret # CEPH_KUBE_SECRET 替换为 client.kube 获取到的key</span><br><span class="line">kubectl create secret generic ceph-user-secret --type=&quot;kubernetes.io/rbd&quot; \</span><br><span class="line">--from-literal=key=AQC3OhNeYrGQLRAA8Xd/e1NUto/fXnGEk6hVMg== \</span><br><span class="line">--namespace=default</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 查看 secret</span><br><span class="line">kubectl get secret ceph-user-secret -o yaml</span><br><span class="line">kubectl get secret ceph-secret -n kube-system -o yaml</span><br></pre></td></tr></table></figure></p>
<p>3.1.3、配置StorageClass<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &gt;storageclass-ceph-rdb.yaml&lt;&lt;EOF</span><br><span class="line">kind: StorageClass</span><br><span class="line">apiVersion: storage.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: dynamic-ceph-rdb</span><br><span class="line">provisioner: ceph.com/rbd</span><br><span class="line">parameters:</span><br><span class="line">  monitors: 192.168.171.135:6789,192.168.171.136:6789,192.168.171.137:6789</span><br><span class="line">  adminId: admin</span><br><span class="line">  adminSecretName: ceph-secret</span><br><span class="line">  adminSecretNamespace: kube-system</span><br><span class="line">  pool: kube</span><br><span class="line">  userId: kube</span><br><span class="line">  userSecretName: ceph-user-secret</span><br><span class="line">  fsType: ext4</span><br><span class="line">  imageFormat: &quot;2&quot;</span><br><span class="line">  imageFeatures: &quot;layering&quot;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure></p>
<p>3.1.4、创建yaml<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl apply -f storageclass-ceph-rdb.yaml</span><br></pre></td></tr></table></figure></p>
<p>3.1.5、查看sc<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl get sc</span><br></pre></td></tr></table></figure></p>
<h3 id="四、测试使用"><a href="#四、测试使用" class="headerlink" title="四、测试使用"></a>四、测试使用</h3><p>1、创建pvc测试<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &gt;ceph-rdb-pvc-test.yaml&lt;&lt;EOF</span><br><span class="line">kind: PersistentVolumeClaim</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  name: ceph-rdb-claim</span><br><span class="line">spec:</span><br><span class="line">  accessModes:     </span><br><span class="line">    - ReadWriteOnce</span><br><span class="line">  storageClassName: dynamic-ceph-rdb</span><br><span class="line">  resources:</span><br><span class="line">    requests:</span><br><span class="line">      storage: 2Gi</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">kubectl apply -f ceph-rdb-pvc-test.yaml</span><br></pre></td></tr></table></figure></p>
<p>2、查看<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@k8s-master1 ~]# kubectl get pvc</span><br><span class="line">NAME             STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS       AGE</span><br><span class="line">ceph-rdb-claim   Bound    pvc-e5f13194-67db-4d98-b69c-5a4272c2498d   2Gi        RWO            dynamic-ceph-rdb   7m10s</span><br><span class="line"></span><br><span class="line">[root@k8s-master1 ~]# kubectl get pv</span><br><span class="line"></span><br><span class="line">NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS        CLAIM                                      STORAGECLASS          REASON   AGE</span><br><span class="line">pvc-e5f13194-67db-4d98-b69c-5a4272c2498d   2Gi        RWO            Delete           Bound         default/ceph-rdb-claim                     dynamic-ceph-rdb       48s</span><br></pre></td></tr></table></figure></p>
<p>3、创建 nginx pod 挂载测试<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &gt;nginx-pod.yaml&lt;&lt;EOF</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx-pod1</span><br><span class="line">  labels:</span><br><span class="line">    name: nginx-pod1</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: nginx-pod1</span><br><span class="line">    image: nginx:alpine</span><br><span class="line">    ports:</span><br><span class="line">    - name: web</span><br><span class="line">      containerPort: 80</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - name: ceph-rdb</span><br><span class="line">      mountPath: /usr/share/nginx/html</span><br><span class="line">  volumes:</span><br><span class="line">  - name: ceph-rdb</span><br><span class="line">    persistentVolumeClaim:</span><br><span class="line">      claimName: ceph-rdb-claim</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">kubectl apply -f nginx-pod.yaml</span><br></pre></td></tr></table></figure></p>
<p>4、查看<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl get pods -o wide</span><br></pre></td></tr></table></figure></p>
<p>5、修改文件内容<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl exec -ti nginx-pod1 -- /bin/sh -c &apos;echo Hello World from Ceph RBD!!! &gt; /usr/share/nginx/html/index.html&apos; # 访问测试</span><br></pre></td></tr></table></figure></p>
<p>6、访问测试<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">POD_ID=$(kubectl get pods -o wide | grep nginx-pod1 | awk &apos;&#123;print $6&#125;&apos;)</span><br><span class="line"></span><br><span class="line">curl http://$POD_ID #测试</span><br></pre></td></tr></table></figure></p>
<p>7、清理<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl delete -f nginx-pod.yaml</span><br><span class="line">kubectl delete -f ceph-rdb-pvc-test.yaml</span><br></pre></td></tr></table></figure></p>
<hr>
<h3 id="五、POD使用CephFS做为持久数据卷"><a href="#五、POD使用CephFS做为持久数据卷" class="headerlink" title="五、POD使用CephFS做为持久数据卷"></a>五、POD使用CephFS做为持久数据卷</h3><p>CephFS方式支持k8s的pv的3种访问模式ReadWriteOnce，ReadOnlyMany ，ReadWriteMany</p>
<h4 id="5-1、Ceph端创建CephFS-pool"><a href="#5-1、Ceph端创建CephFS-pool" class="headerlink" title="5.1、Ceph端创建CephFS pool"></a>5.1、Ceph端创建CephFS pool</h4><p>1、如下操作在ceph的mon或者admin节点<br>CephFS需要使用两个Pool来分别存储数据和元数据<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ceph osd pool create fs_data 128</span><br><span class="line">ceph osd pool create fs_metadata 128</span><br><span class="line">ceph osd lspools</span><br></pre></td></tr></table></figure></p>
<p>2、创建一个CephFS<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ceph fs new cephfs fs_metadata fs_data</span><br></pre></td></tr></table></figure></p>
<p>3、查看<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ceph fs ls</span><br></pre></td></tr></table></figure></p>
<h4 id="5-2、部署-cephfs-provisioner"><a href="#5-2、部署-cephfs-provisioner" class="headerlink" title="5.2、部署 cephfs-provisioner"></a>5.2、部署 cephfs-provisioner</h4><p>1、使用社区提供的cephfs-provisioner<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &gt;external-storage-cephfs-provisioner.yaml&lt;&lt;EOF</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Namespace</span><br><span class="line">metadata:</span><br><span class="line">   name: cephfs</span><br><span class="line">   labels:</span><br><span class="line">     name: cephfs</span><br><span class="line"> </span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: cephfs-provisioner</span><br><span class="line">  namespace: cephfs</span><br><span class="line"> </span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: Role</span><br><span class="line">metadata:</span><br><span class="line">  name: cephfs-provisioner</span><br><span class="line">  namespace: cephfs</span><br><span class="line">rules:</span><br><span class="line">  - apiGroups: [&quot;&quot;]</span><br><span class="line">    resources: [&quot;secrets&quot;]</span><br><span class="line">    verbs: [&quot;create&quot;, &quot;get&quot;, &quot;delete&quot;]</span><br><span class="line">  - apiGroups: [&quot;&quot;]</span><br><span class="line">    resources: [&quot;endpoints&quot;]</span><br><span class="line">    verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;, &quot;create&quot;, &quot;update&quot;, &quot;patch&quot;]</span><br><span class="line"> </span><br><span class="line">---</span><br><span class="line">kind: ClusterRole</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: cephfs-provisioner</span><br><span class="line">  namespace: cephfs</span><br><span class="line">rules:</span><br><span class="line">  - apiGroups: [&quot;&quot;]</span><br><span class="line">    resources: [&quot;persistentvolumes&quot;]</span><br><span class="line">    verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;, &quot;create&quot;, &quot;delete&quot;]</span><br><span class="line">  - apiGroups: [&quot;&quot;]</span><br><span class="line">    resources: [&quot;persistentvolumeclaims&quot;]</span><br><span class="line">    verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;, &quot;update&quot;]</span><br><span class="line">  - apiGroups: [&quot;storage.k8s.io&quot;]</span><br><span class="line">    resources: [&quot;storageclasses&quot;]</span><br><span class="line">    verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;]</span><br><span class="line">  - apiGroups: [&quot;&quot;]</span><br><span class="line">    resources: [&quot;events&quot;]</span><br><span class="line">    verbs: [&quot;create&quot;, &quot;update&quot;, &quot;patch&quot;]</span><br><span class="line">  - apiGroups: [&quot;&quot;]</span><br><span class="line">    resources: [&quot;services&quot;]</span><br><span class="line">    resourceNames: [&quot;kube-dns&quot;,&quot;coredns&quot;]</span><br><span class="line">    verbs: [&quot;list&quot;, &quot;get&quot;]</span><br><span class="line">  - apiGroups: [&quot;&quot;]</span><br><span class="line">    resources: [&quot;secrets&quot;]</span><br><span class="line">    verbs: [&quot;get&quot;, &quot;create&quot;, &quot;delete&quot;]</span><br><span class="line">  - apiGroups: [&quot;policy&quot;]</span><br><span class="line">    resourceNames: [&quot;cephfs-provisioner&quot;]</span><br><span class="line">    resources: [&quot;podsecuritypolicies&quot;]</span><br><span class="line">    verbs: [&quot;use&quot;]</span><br><span class="line"> </span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: RoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: cephfs-provisioner</span><br><span class="line">  namespace: cephfs</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: Role</span><br><span class="line">  name: cephfs-provisioner</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: cephfs-provisioner</span><br><span class="line"> </span><br><span class="line">---</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: cephfs-provisioner</span><br><span class="line">subjects:</span><br><span class="line">  - kind: ServiceAccount</span><br><span class="line">    name: cephfs-provisioner</span><br><span class="line">    namespace: cephfs</span><br><span class="line">roleRef:</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: cephfs-provisioner</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line"> </span><br><span class="line">---</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: cephfs-provisioner</span><br><span class="line">  namespace: cephfs</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: cephfs-provisioner</span><br><span class="line">  replicas: 1</span><br><span class="line">  strategy:</span><br><span class="line">    type: Recreate</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: cephfs-provisioner</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: cephfs-provisioner</span><br><span class="line">        image: &quot;quay.io/external_storage/cephfs-provisioner:latest&quot;</span><br><span class="line">        env:</span><br><span class="line">        - name: PROVISIONER_NAME</span><br><span class="line">          value: ceph.com/cephfs</span><br><span class="line">        command:</span><br><span class="line">        - &quot;/usr/local/bin/cephfs-provisioner&quot;</span><br><span class="line">        args:</span><br><span class="line">        - &quot;-id=cephfs-provisioner-1&quot;</span><br><span class="line">        - &quot;-disable-ceph-namespace-isolation=true&quot;</span><br><span class="line">      serviceAccount: cephfs-provisioner</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">kubectl apply -f external-storage-cephfs-provisioner.yaml</span><br></pre></td></tr></table></figure></p>
<p>2、查看状态 等待running之后 再进行后续的操作<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl get pod -n cephfs</span><br></pre></td></tr></table></figure></p>
<h4 id="5-3、配置-storageclass"><a href="#5-3、配置-storageclass" class="headerlink" title="5.3、配置 storageclass"></a>5.3、配置 storageclass</h4><p>1、查看key 在ceph的mon或者admin节点<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ceph auth get-key client.admin</span><br></pre></td></tr></table></figure></p>
<p>2、# 创建 admin secret # CEPH_ADMIN_SECRET 替换为 client.admin 获取到的key # 如果在测试 ceph rbd 方式已经添加 可以略过此步骤<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl create secret generic ceph-secret --type=&quot;kubernetes.io/rbd&quot; \</span><br><span class="line">--from-literal=key=AQCeEwpeo+I8HRAAnBphr8lyGc6+JBT7jU7rgA== \</span><br><span class="line">--namespace=kube-system</span><br></pre></td></tr></table></figure></p>
<p>3、查看 secret<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl get secret ceph-secret -n kube-system -o yaml</span><br></pre></td></tr></table></figure></p>
<p>4、配置 StorageClass<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &gt;storageclass-cephfs.yaml&lt;&lt;EOF</span><br><span class="line">kind: StorageClass</span><br><span class="line">apiVersion: storage.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: dynamic-cephfs</span><br><span class="line">provisioner: ceph.com/cephfs</span><br><span class="line">parameters:</span><br><span class="line">    monitors: 192.168.171.135:6789,192.168.171.136:6789,192.168.171.137:6789</span><br><span class="line">    adminId: admin</span><br><span class="line">    adminSecretName: ceph-secret</span><br><span class="line">    adminSecretNamespace: &quot;kube-system&quot;</span><br><span class="line">    claimRoot: /volumes/kubernetes</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure></p>
<p>5、创建<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl apply -f storageclass-cephfs.yaml</span><br></pre></td></tr></table></figure></p>
<p>6、查看<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl get sc</span><br></pre></td></tr></table></figure></p>
<h4 id="5-4、测试使用"><a href="#5-4、测试使用" class="headerlink" title="5.4、测试使用"></a>5.4、测试使用</h4><p>1、创建pvc测试<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &gt;cephfs-pvc-test.yaml&lt;&lt;EOF</span><br><span class="line">kind: PersistentVolumeClaim</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  name: cephfs-claim</span><br><span class="line">spec:</span><br><span class="line">  accessModes:     </span><br><span class="line">    - ReadWriteOnce</span><br><span class="line">  storageClassName: dynamic-cephfs</span><br><span class="line">  resources:</span><br><span class="line">    requests:</span><br><span class="line">      storage: 2Gi</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">kubectl apply -f cephfs-pvc-test.yaml</span><br></pre></td></tr></table></figure></p>
<p>2、查看<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@k8s-master1 ceph-all]# kubectl get pvc</span><br><span class="line">NAME           STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS     AGE</span><br><span class="line">cephfs-claim   Bound    pvc-50ebdaab-c6ad-47ad-86cb-149327481a67   2Gi        RWO            dynamic-cephfs   4s</span><br><span class="line">[root@k8s-master1 ceph-all]# kubectl get pv</span><br><span class="line">NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS     CLAIM                    STORAGECLASS       REASON   AGE</span><br><span class="line">pvc-50ebdaab-c6ad-47ad-86cb-149327481a67   2Gi        RWO            Delete           Bound      default/cephfs-claim     dynamic-cephfs              6s</span><br></pre></td></tr></table></figure></p>
<p>3、创建 nginx pod 挂载测试<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &gt;nginx-pod.yaml&lt;&lt;EOF</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx-pod2</span><br><span class="line">  labels:</span><br><span class="line">    name: nginx-pod2</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: nginx-pod2</span><br><span class="line">    image: nginx:alpine</span><br><span class="line">    ports:</span><br><span class="line">    - name: web</span><br><span class="line">      containerPort: 80</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - name: cephfs</span><br><span class="line">      mountPath: /usr/share/nginx/html</span><br><span class="line">  volumes:</span><br><span class="line">  - name: cephfs</span><br><span class="line">    persistentVolumeClaim:</span><br><span class="line">      claimName: cephfs-claim</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">kubectl apply -f nginx-pod.yaml</span><br></pre></td></tr></table></figure></p>
<p> 4、查看<br> <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl get pods -o wide</span><br></pre></td></tr></table></figure></p>
<p> 5、修改文件内容<br> <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl exec -ti nginx-pod2 -- /bin/sh -c &apos;echo Hello World from CephFS!!! &gt; /usr/share/nginx/html/index.html&apos; # 访问测试</span><br></pre></td></tr></table></figure></p>
<p>6、访问pod测试<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">POD_ID=$(kubectl get pods -o wide | grep nginx-pod2 | awk &apos;&#123;print $6&#125;&apos;)</span><br><span class="line">curl http://$POD_ID</span><br></pre></td></tr></table></figure></p>
<p>7、清理<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl delete -f nginx-pod.yaml</span><br><span class="line">kubectl delete -f cephfs-pvc-test.yaml</span><br></pre></td></tr></table></figure></p>

            <hr>
          </div>
          <br>
          <div>
            <p>
            
              <span>
                <i class="iconfont icon-inbox"></i>
                
                  <a class="hover-with-bg" href="/categories/K8s,%20ceph">K8s, ceph</a>
                  &nbsp;
                
              </span>&nbsp;&nbsp;
            
            
              <span>
                <i class="iconfont icon-tag"></i>
                
                  <a class="hover-with-bg" href="/tags/K8S">K8S</a>
                
              </span>
            
            </p>
            
              <p class="note note-warning">本博客所有文章除特别声明外，均采用 <a href="https://zh.wikipedia.org/wiki/Wikipedia:CC_BY-SA_3.0%E5%8D%8F%E8%AE%AE%E6%96%87%E6%9C%AC" rel="nofollow noopener">CC BY-SA 3.0协议</a> 。转载请注明出处！</p>
            
          </div>
        </div>
      </div>
    </div>
    <div class="d-none d-lg-block col-lg-2 toc-container">
      
  <div id="toc">
    <p class="h4"><i class="far fa-list-alt"></i>&nbsp;ディレクトリ</p>
    <div id="tocbot"></div>
  </div>

    </div>
  </div>
</div>

<!-- custom -->


<!-- Comments -->
<div class="col-lg-7 mx-auto nopadding-md">
  <div class="container comments mx-auto" id="comments">
    
  </div>
</div>

    
  </main>

  
    <a class="z-depth-1" id="scroll-top-button" href="#" role="button">
      <i class="fa fa-chevron-up scroll-top-arrow" aria-hidden="true"></i>
    </a>
  

  
    <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel" aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">検索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">キーワード</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
  

  <footer class="mt-5">
  <div class="text-center py-3">
    <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><b>Hexo</b></a>
    <i class="iconfont icon-love"></i>
    <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"> <b>Fluid</b></a>
    <br>

    
  
    <!-- 不蒜子统计PV -->
    
    &nbsp;<span id="busuanzi_container_site_pv">总访问量 
          <span id="busuanzi_value_site_pv"></span> 次</span>&nbsp;
  
  
    <!-- 不蒜子统计UV -->
    
    &nbsp;<span id="busuanzi_container_site_uv">总访客数 
            <span id="busuanzi_value_site_uv"></span> 人</span>&nbsp;
  
  <br>



    


    <!-- cnzz Analytics icon -->
    

  </div>
</footer>

<!-- SCRIPTS -->
<script src="/lib/jquery/jquery.min.js"></script>
<script src="/lib/popper/popper.min.js"></script>
<script src="/lib/bootstrap/js/bootstrap.min.js"></script>
<script src="/lib/mdbootstrap/js/mdb.min.js"></script>
<script src="/js/main.js"></script>


  <script src="/js/lazyload.js"></script>



  
    <script src="/lib/tocbot/tocbot.min.js"></script>
  
  <script src="/js/post.js"></script>



  <script src="/lib/smooth-scroll/smooth-scroll.min.js"></script>



  <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>


<!-- Plugins -->


  

  

  

  

  <!-- cnzz Analytics -->
  



  <script src="/lib/prettify/prettify.min.js"></script>
  <script>
    $(document).ready(function () {
      $('pre').addClass('prettyprint  ');
      prettyPrint();
    })
  </script>



  <script src="/lib/typed/typed.min.js"></script>
  <script>
    var typed = new Typed('#subtitle', {
      strings: [
        '  ',
        "六、K8S 使用Ceph存储&nbsp;",
      ],
      cursorChar: "_",
      typeSpeed: 70,
      loop: false,
    });
    typed.stop();
    $(document).ready(function () {
      $(".typed-cursor").addClass("h2");
      typed.start();
    });
  </script>



  <script src="/lib/anchor/anchor.min.js"></script>
  <script>
    anchors.options = {
      placement: "right",
      visible: "false",
      
    };
    var el = "h1,h2,h3,h4,h5,h6".split(",");
    var res = [];
    for (item of el) {
      res.push(".markdown-body > " + item)
    }
    anchors.add(res.join(", "))
  </script>



  <script src="/js/local-search.js"></script>
  <script>
    var path = "/local-search.xml";
    var inputArea = document.querySelector("#local-search-input");
    inputArea.onclick = function () {
      getSearchFile(path);
      this.onclick = null
    }
  </script>



  <script src="/lib/fancybox/jquery.fancybox.min.js"></script>
  <script>
    $("#post img:not(.no-zoom img, img[no-zoom])").each(
      function () {
        var element = document.createElement("a");
        $(element).attr("data-fancybox", "images");
        $(element).attr("href", $(this).attr("src"));
        $(this).wrap(element);
      }
    );
  </script>











</body>
</html>
