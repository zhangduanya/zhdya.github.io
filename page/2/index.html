<!DOCTYPE html>
<html lang="zh-CN">





<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/apple-touch-icon.png">
  <link rel="icon" type="image/png" href="/img/favicon.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="description" content="Tough times never last, but tough people do.">
  <meta name="author" content="Zhdya">
  <meta name="keywords" content="">
  <title>不认命？就拼命！</title>

  <link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
<link rel="stylesheet" href="/lib/bootstrap/css/bootstrap.min.css">
<link rel="stylesheet" href="/lib/mdbootstrap/css/mdb.min.css">
<link rel="stylesheet" href="/lib/github-markdown/github-markdown.min.css">
<link rel="stylesheet" href="//at.alicdn.com/t/font_1067060_qzomjdt8bmp.css">


  <link rel="stylesheet" href="/lib/prettify/tomorrow-night-eighties.min.css">

<link rel="stylesheet" href="/css/main.css">


  <link rel="stylesheet" href="/lib/fancybox/jquery.fancybox.min.css">


</head>


<body>
  <header style="height: 77vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">&nbsp;<strong>不认命？就拼命！</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/">首页</a>
          </li>
        
          
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/archives/">归档</a>
          </li>
        
          
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/categories/">分类</a>
          </li>
        
          
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/tags/">标签</a>
          </li>
        
          
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/about/">关于</a>
          </li>
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;&nbsp;<i class="iconfont icon-search"></i>&nbsp;&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="view intro-2" id="background"
         style="background: url('http://myimage.okay686.cn/okay686cn/20200201/s2jd1FEBAEvP.png')no-repeat center center;
           background-size: cover;
           background-attachment: fixed;">
      <div class="full-bg-img">
        <div class="mask rgba-black-light flex-center">
          <div class="container text-center white-text fadeInUp">
            <span class="h2" id="subtitle">
              
            </span>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      <div class="container nopadding-md">
        <div class="py-5 z-depth-3" id="board">
          
          <div class="container">
            <div class="row">
              <div class="col-12 col-md-10 m-auto">
                


  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2019/12/23/一、Ceph介绍/">
        <p class="h4 index-header">一、Ceph介绍</p>
        
        
          
        
        <div class="index-excerpt">
          <div class="index-text mb-1">为什么要用Ceph
Ceph是当前非常流行的开源分布式存储系统，具有高扩展性、高性能、高可靠性等优点，同时提供块存储服务(rbd)、对象存储服务(rgw)以及文件系统存储服务(cephfs)，Ceph在存储的时候充分利用存储节点的计算能力，在存储每一个数据时都会通过计算得出该数据的位置，尽量的分布均衡。。目前也是OpenStack的主流后端存储，随着OpenStack在云计算领域的广泛使用，ceph也变得更加炙手可热。国内目前使用ceph搭建分布式存储系统较为成功的企业有x-sky,深圳元核云，上海UCloud等三家企业。


Ceph架构介绍
Ceph使用RADOS提供对象存储，通过librados封装库提供多种存储方式的文件和对象转换。外层通过RGW（Object，有原生的API，而且也兼容Swift和S3的API，适合单客户端使用）、RBD（Block，支持精简配置、快照、克隆，适合多客户端有目录结构）、CephFS（File，Posix接口，支持快照，社会和更新变动少的数据，没有目录结构不能直接打开）将数据写入存储。

高性能a. 摒弃了传统的集中式存储元数据寻址的方案，采用C</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2019-12-23&nbsp;&nbsp;
        
        
          <i class="iconfont icon-inbox"></i>
          
            <a href="/categories/K8S,%20ceph">K8S, ceph</a>&nbsp;
          &nbsp;
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/K8S">K8S</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2019/12/22/K8S集群网路Calico网络组件实践(BGP、RR、IPIP)/">
        <p class="h4 index-header">Calico网络组件实践(BGP、RR、IPIP)</p>
        
        
          
        
        <div class="index-excerpt">
          <div class="index-text mb-1">Kubernetes网络方案之 CalicoCalico是一个纯三层的数据中心网络方案，Calico支持广泛的平台，包括Kubernetes、OpenStack等。
Calico 在每一个计算节点利用 Linux Kernel 实现了一个高效的虚拟路由器（ vRouter） 来负责数据转发，而每个 vRouter 通过 BGP 协议负责把自己上运行的 workload 的路由信息向整个 Calico 网络内传播。
此外，Calico  项目还实现了 Kubernetes 网络策略，提供ACL功能。
1、BGP概述实际上，Calico项目提供的网络解决方案，与Flannel的host-gw模式几乎一样。也就是说，Calico也是基于路由表实现容器数据包转发，但不同于Flannel使用flanneld进程来维护路由信息的做法，而Calico项目使用BGP协议来自动维护整个集群的路由信息。
BGP英文全称是Border Gateway Protocol，即边界网关协议，它是一种自治系统间的动态路由发现协议，与其他 BGP 系统交换网络可达信息。 
为了能让你更清楚理解BGP，举个例子：

在</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2019-12-22&nbsp;&nbsp;
        
        
          <i class="iconfont icon-inbox"></i>
          
            <a href="/categories/K8S">K8S</a>&nbsp;
          &nbsp;
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/Kubernetes">Kubernetes</a>&nbsp;
          
            <a href="/tags/K8S">K8S</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2019/12/22/K8S集群网络生产级探究/">
        <p class="h4 index-header">K8S集群网络生产级探究</p>
        
        
          
        
        <div class="index-excerpt">
          <div class="index-text mb-1">K8S集群网络网络基础知识1、公司网络架构

路由器：网络出口
核心层：主要完成数据高效转发、链路备份等
汇聚层：网络策略、安全、工作站交换机的接入、VLAN之间通信等功能
接入层：工作站的接入

1、一个局域网内主机A（10）和主机B（20）之间通讯流程：网段：192.168.31.0/24源IP和目的IP均在同一子网下。四元组：源IP 源MAC 目的IP 目的MAC- 在本机查找ARP缓存表，ARP广播包询问20的MAC地址是多少。 2、主机A（10）和主机B（20）不在同一个局域网内之间通讯流程：VLAN1:192.168.31.0/24VLAN2:192.168.32.0/24- 主机A自顶向下将数据封装成链路层帧，缓存在主机A的适配器缓存中，主机A通过查看适配器中ARP表对应的MAC地址，将链路层帧发送到与其连接的第一跳路由器上，当链路层帧到达该路由器后，路由器根据自身的路由器转发表转发到指定的出口IP再一层层转向目的VLAN。
2、交换技术有想过局域网内主机怎么通信的？主机访问外网又是怎么通信的？
想要搞懂这些问题得从交换机、路由器讲起。

交换机工作在OSI参考模型的第二</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2019-12-22&nbsp;&nbsp;
        
        
          <i class="iconfont icon-inbox"></i>
          
            <a href="/categories/K8S">K8S</a>&nbsp;
          &nbsp;
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/Kubernetes">Kubernetes</a>&nbsp;
          
            <a href="/tags/K8S">K8S</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2019/12/22/K8S集群网络Flannel网络组件实践(vxlan、host-gw)/">
        <p class="h4 index-header">Flannel网络组件实践(vxlan、host-gw)</p>
        
        
          
        
        <div class="index-excerpt">
          <div class="index-text mb-1">Kubernetes网络组件之 FlannelFlannel是CoreOS维护的一个网络组件，Flannel为每个Pod提供全局唯一的IP，Flannel使用ETCD来存储Pod子网与Node IP之间的关系。flanneld守护进程在每台主机上运行，并负责维护ETCD信息和路由数据包。
1、Flannel 部署https://github.com/coreos/flannel 
kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml
2、 Flannel工作模式及原理Flannel支持多种数据转发方式：

UDP：最早支持的一种方式，由于性能最差，目前已经弃用。
VXLAN：Overlay Network方案，源数据包封装在另一种网络包里面进行路由转发和通信。==（100台左右node适用）==
Host-GW：Flannel通过在各个节点上的Agent进程，将容器网络的路由信息刷到主机的路由表上，这样一来所有的主机都有整个容器网络的</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2019-12-22&nbsp;&nbsp;
        
        
          <i class="iconfont icon-inbox"></i>
          
            <a href="/categories/K8S">K8S</a>&nbsp;
          &nbsp;
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/Kubernetes">Kubernetes</a>&nbsp;
          
            <a href="/tags/K8S">K8S</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2019/12/18/K8s Ingress Nginx使用/">
        <p class="h4 index-header">K8s Ingress Nginx使用</p>
        
        
          
        
        <div class="index-excerpt">
          <div class="index-text mb-1">案例1（基本转发，https配置与annotations基础使用）apiVersion: extensions/v1beta1kind: Ingressmetadata:  name: ingress  namespace: test  annotations:    kubernetes.io/ingress.class: &quot;nginx&quot;    nginx.ingress.kubernetes.io/use-regex: &quot;true&quot;spec:  tls:  - hosts:    - nginx-a.gogen.cn    secretName: gogen.cn  rules:  - host: nginx-a.gogen.cn    http:      paths:      - path: /        backend:          serviceName: nginx-a          servicePort: 80      - path: /.*.(txt|css|doc)        backend:     </div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2019-12-18&nbsp;&nbsp;
        
        
          <i class="iconfont icon-inbox"></i>
          
            <a href="/categories/K8S">K8S</a>&nbsp;
          &nbsp;
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/Kubernetes">Kubernetes</a>&nbsp;
          
            <a href="/tags/K8S">K8S</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2019/12/17/k8s二进制安装环境下证书过期问题/">
        <p class="h4 index-header">k8s二进制安装环境下证书过期问题</p>
        
        
          
        
        <div class="index-excerpt">
          <div class="index-text mb-1">k8s配置信息的工作目录一般为/etc/kubernetes，证书目录一般为/etc/kubernetes/ssl
一、重新生成证书当你的kubernetes报错：certificate has expired or is not yet valid，可以通过命令：openssl x509 -in [证书全路径] -noout -text查看证书详情。
1、备份[root@zhdya]# cd /etc/kubernetes;[root@zhdya]# cp kubelet.kubeconfig kubelet.kubeconfig.bak;[root@zhdya]# mkdir sslbak &amp;&amp; cp ssl/ sslbak;
2、清理[root@zhdya]# rm -f kubelet.kubeconfig;[root@zhdya]# rm ssl/kubelet.*;
3. 重启kubelete[root@zhdya]# systemctl  restart kubelet &amp;&amp; systemctl  status  kubelet
4. 使用</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2019-12-17&nbsp;&nbsp;
        
        
          <i class="iconfont icon-inbox"></i>
          
            <a href="/categories/K8S">K8S</a>&nbsp;
          &nbsp;
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/Kubernetes">Kubernetes</a>&nbsp;
          
            <a href="/tags/K8S">K8S</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2019/12/16/Helm应用包管理器（上）/">
        <p class="h4 index-header">Helm应用包管理器（上）</p>
        
        
          
        
        <div class="index-excerpt">
          <div class="index-text mb-1">三、Helm应用包管理器3.1 为什么需要Helm？K8S上的应用对象，都是由特定的资源描述组成，包括deployment、service等。都保存各自文件中或者集中写到一个配置文件。然后kubectl apply –f 部署。

如果应用只由一个或几个这样的服务组成，上面部署方式足够了。
而对于一个复杂的应用，会有很多类似上面的资源描述文件，例如微服务架构应用，组成应用的服务可能多达十个，几十个。如果有更新或回滚应用的需求，可能要修改和维护所涉及的大量资源文件，而这种组织和管理应用的方式就显得力不从心了。
且由于缺少对发布过的应用版本管理和控制，使Kubernetes上的应用维护和更新等面临诸多的挑战，主要面临以下问题：

如何将这些服务作为一个整体管理
这些资源文件如何高效复用
不支持应用级别的版本管理

3.2 Helm 介绍Helm是一个Kubernetes的包管理工具，就像Linux下的包管理器，如yum/apt等，可以很方便的将之前打包好的yaml文件部署到kubernetes上。
Helm有两个重要概念：

helm：一个命令行客户端工具，主要用于Kubernetes应用</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2019-12-16&nbsp;&nbsp;
        
        
          <i class="iconfont icon-inbox"></i>
          
            <a href="/categories/K8S">K8S</a>&nbsp;
          &nbsp;
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/Kubernetes">Kubernetes</a>&nbsp;
          
            <a href="/tags/K8S">K8S</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2019/12/15/Java参数深入分析/">
        <p class="h4 index-header">记一次java_MetaspaceSize设置不当导致的问题</p>
        
        
          
        
        <div class="index-excerpt">
          <div class="index-text mb-1">先来了解下：
内存的分配及回收–堆中的新生代和老年代：java堆被分为两部分， 一部分被称为新生代， 一部分称为老年代， 他们的比例通常为 1：2

一、堆（新生代、老年代）与元空间。1.1、新生代：主要是用来存放新生的对象。一般占据堆空间的1/3，由于频繁创建对象，所以新生代会频繁触发MinorGC进行垃圾回收。新生代分为Eden区、ServivorFrom、ServivorTo三个区，==比例为 8：1：1==。

Eden区：Java新对象的出生地(如果新创建的对象占用内存很大则直接分配给老年代)。
1.1.1、MinorGC 触发机制：
当Eden区内存不够的时候就会触发一次MinorGc，对新生代区进行一次垃圾回收。

ServivorTo：保留了一次MinorGc过程中的幸存者。
ServivorFrom: 上一次GC的幸存者，作为这一次GC的被扫描者。当JVM无法为新建对象分配内存空间的时候(Eden区满的时候)，JVM触发MinorGc。因此新生代空间占用越低，MinorGc越频繁。
每次对象会存在于Eden区和一个Survivor区， 当内存不够时，触发GC，然后把依</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2019-12-15&nbsp;&nbsp;
        
        
          <i class="iconfont icon-inbox"></i>
          
            <a href="/categories/JAVA">JAVA</a>&nbsp;
          &nbsp;
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/Java">Java</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2019/12/13/K8S深度理解弹性伸缩2/">
        <p class="h4 index-header">K8S弹性伸缩之Pods 资源扩容方案</p>
        
        
          
        
        <div class="index-excerpt">
          <div class="index-text mb-1">Pod自动扩容/缩容（HPA）Horizontal Pod Autoscaler（HPA，Pod水平自动伸缩），根据资源利用率或者自定义指标自动调整replication controller, deployment 或 replica set，实现部署的自动扩展和缩减，让部署的规模接近于实际服务的负载。HPA不适于无法缩放的对象，例如DaemonSet。

1、HPA基本原理Kubernetes 中的 Metrics Server 持续采集所有 Pod 副本的指标数据。HPA 控制器通过 Metrics Server 的 API（Heapster 的 API 或聚合 API）获取这些数据，基于用户定义的扩缩容规则进行计算，得到目标 Pod 副本数量。当目标 Pod 副本数量与当前副本数量不同时，HPA 控制器就向 Pod 的副本控制器（Deployment、RC 或 ReplicaSet）发起 scale 操作，调整 Pod 的副本数量，完成扩缩容操作。如图所示。

在弹性伸缩中，冷却周期是不能逃避的一个话题， 由于评估的度量标准是动态特性，副本的数量可能会不断波动。有时被称为颠簸，</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2019-12-13&nbsp;&nbsp;
        
        
          <i class="iconfont icon-inbox"></i>
          
            <a href="/categories/K8S">K8S</a>&nbsp;
          &nbsp;
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/Kubernetes">Kubernetes</a>&nbsp;
          
            <a href="/tags/K8S">K8S</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2019/12/13/K8S深度理解弹性伸缩4/">
        <p class="h4 index-header">K8S弹性伸缩之基于Prometheus QPS指标的HPA</p>
        
        
          
        
        <div class="index-excerpt">
          <div class="index-text mb-1">基于Prometheus自定义指标缩放资源指标只包含CPU、内存，一般来说也够了。但如果想根据自定义指标:如请求qps/5xx错误数来实现HPA，就需要使用自定义指标了，目前比较成熟的实现是 Prometheus Custom Metrics。自定义指标由Prometheus来提供，再利用k8s-prometheus-adpater聚合到apiserver，实现和核心指标（metric-server)同样的效果。

1、部署PrometheusPrometheus（普罗米修斯）是一个最初在SoundCloud上构建的监控系统。自2012年成为社区开源项目，拥有非常活跃的开发人员和用户社区。为强调开源及独立维护，Prometheus于2016年加入云原生云计算基金会（CNCF），成为继Kubernetes之后的第二个托管项目。
Prometheus 特点：

自动采集，服务发现；

多维数据模型：由度量名称和键值对标识的时间序列数据；

PromSQL：一种灵活的查询语言，可以利用多维数据完成复杂的查询；

不依赖分布式存储，单个服务器节点可直接工作；

基于HTTP的pull方式采集时</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2019-12-13&nbsp;&nbsp;
        
        
          <i class="iconfont icon-inbox"></i>
          
            <a href="/categories/K8S">K8S</a>&nbsp;
          &nbsp;
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/Kubernetes">Kubernetes</a>&nbsp;
          
            <a href="/tags/K8S">K8S</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2019/12/13/K8S深度理解弹性伸缩/">
        <p class="h4 index-header">K8S弹性伸缩之Nodes 资源扩容（CA，Ansible）</p>
        
        
          
        
        <div class="index-excerpt">
          <div class="index-text mb-1">弹性伸缩1 传统弹性伸缩的困境从传统意义上，弹性伸缩主要解决的问题是容量规划与实际负载的矛盾。

蓝色水位线表示集群资源容量随着负载的增加不断扩容，红色曲线表示集群资源实际负载变化。
弹性伸缩就是要解决当实际负载增大，而集群资源容量没来得及反应的问题。
1、Kubernetes中弹性伸缩存在的问题常规的做法是给集群资源预留保障集群可用，通常20%左右。这种方式看似没什么问题，但放到Kubernetes中，就会发现如下2个问题。

机器规格不统一造成机器利用率百分比碎片化
在一个Kubernetes集群中，通常不只包含一种规格的机器，假设集群中存在4C8G与16C32G两种规格的机器，对于10%的资源预留，这两种规格代表的意义是完全不同的。



特别是在缩容的场景下，为了保证缩容后集群稳定性，我们一般会一个节点一个节点从集群中摘除，那么如何判断节点是否可以摘除其利用率百分比就是重要的指标。此时如果大规格机器有较低的利用率被判断缩容，那么很有可能会造成节点缩容后，容器重新调度后的争抢。如果优先缩容小规格机器，则可能造成缩容后资源的大量冗余。

机器利用率不单纯依靠宿主机计算
在大部分生产</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2019-12-13&nbsp;&nbsp;
        
        
          <i class="iconfont icon-inbox"></i>
          
            <a href="/categories/K8S">K8S</a>&nbsp;
          &nbsp;
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/Kubernetes">Kubernetes</a>&nbsp;
          
            <a href="/tags/K8S">K8S</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2019/12/13/K8S深度理解弹性伸缩3/">
        <p class="h4 index-header">K8S弹性伸缩之基于Metrics Server CPU指标的HPA</p>
        
        
          
        
        <div class="index-excerpt">
          <div class="index-text mb-1">基于CPU指标缩放1、 Kubernetes API Aggregation什么是k8sapi聚合？
它是允许k8s的开发人员编写一个自己的服务，可以把这个服务注册到k8s的api里面，这样，就像k8s自己的api一样，你的服务只要运行在k8s集群里面，k8s 的Aggregate通过service名称就可以转发到你写的service里面去了。
当然看如下图↓：你也可以把agg当作一个nginx的反代，它就是代理层。
在 Kubernetes 1.7 版本引入了聚合层，允许第三方应用程序通过将自己注册到kube-apiserver上，仍然通过 API Server 的 HTTP URL 对新的 API 进行访问和操作。为了实现这个机制，Kubernetes 在 kube-apiserver 服务中引入了一个 API 聚合层（API Aggregation Layer），用于将扩展 API 的访问请求转发到用户服务的功能。

当你访问 apis/metrics.k8s.io/v1beta1 的时候，实际上访问到的是一个叫作 kube-aggregator 的代理。而 kube-apise</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2019-12-13&nbsp;&nbsp;
        
        
          <i class="iconfont icon-inbox"></i>
          
            <a href="/categories/K8S">K8S</a>&nbsp;
          &nbsp;
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/Kubernetes">Kubernetes</a>&nbsp;
          
            <a href="/tags/K8S">K8S</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2019/12/10/K8S之Ingress-Nginx实现高可用/">
        <p class="h4 index-header">K8S之Ingress-Nginx实现高可用</p>
        
        
          
        
        <div class="index-excerpt">
          <div class="index-text mb-1">承接上文，我们部署好了ingress，为了达到生产级的阈值，我们必须要要配置ingress的高可用：
假定我们在Kubernetes 指定两个worker节点中部署了ingress nginx来为后端的pod做proxy，这时候我们就需要通过keepalived实现高可用，提供对外的VIP，也就是externalLB的upstream只需要绑定此VIP即可。

首先我们要先确保有两个worker节点部署了ingress nginx
在本实验中，环境如下：



IP地址
主机名
描述




10.0.0.31
k8s-master01    


10.0.0.34
k8s-node02
ingress nginx、keepalived


10.0.0.35
k8s-node03
ingress nginx、keepalived



1、查看ingress nginx状态[root@k8s-master01 Ingress]# kubectl get pod -n ingress-nginx -o wideNAME                                 </div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2019-12-10&nbsp;&nbsp;
        
        
          <i class="iconfont icon-inbox"></i>
          
            <a href="/categories/K8S">K8S</a>&nbsp;
          &nbsp;
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/Kubernetes">Kubernetes</a>&nbsp;
          
            <a href="/tags/K8S">K8S</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2019/12/09/k8s之存储卷及pvc/">
        <p class="h4 index-header">k8s之存储卷及pvc</p>
        
        
          
        
        <div class="index-excerpt">
          <div class="index-text mb-1">一、概述因为pod是有生命周期的,pod一重启,里面的数据就没了,所以我们需要数据持久化存储,在k8s中,存储卷不属于容器,而是属于pod,也就是说同一个pod中的容器可以共享一个存储卷,存储卷可以是宿主机上的目录,也可以是挂载在宿主机上的外部设备。
1.1、存储卷类型：
emptyDIR存储卷：pod一重启,存储卷也删除,这叫emptyDir存储卷,一般用于当做临时空间或缓存关系;

hostPath存储卷：宿主机上目录作为存储卷,这种也不是真正意义实现了数据持久性;

SAN(iscsi)或NAS(nfs、cifs)：网络存储设备;

分布式存储：ceph,glusterfs,cephfs,rbd；

云存储：亚马逊的EBS,Azure Disk,阿里云,关键数据一定要有异地备份；


emptyDIR存储卷：vim podtest/pod-vol-demo.yamlapiVersion: v1kind: Podmetadata:  name: pod-demo  namespace: default  labels:    app: myapp    tier: frontend</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2019-12-09&nbsp;&nbsp;
        
        
          <i class="iconfont icon-inbox"></i>
          
            <a href="/categories/K8S">K8S</a>&nbsp;
          &nbsp;
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/Kubernetes">Kubernetes</a>&nbsp;
          
            <a href="/tags/K8S">K8S</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2019/12/07/K8S负载均衡之nginx-ingress/">
        <p class="h4 index-header">K8S负载均衡之nginx-ingress</p>
        
        
          
        
        <div class="index-excerpt">
          <div class="index-text mb-1">++本篇引自多篇大佬文档整合而来，加上自己所理解整理如下：++
一、目前状况：k8s有了coreDNS解决了k8s集群内部通过dns域名的方式相互访问容器服务，但是集群内部的域名无法在外部被访问，也没有解决域名7层负载均衡的问题，而nginx-ingress就是为了解决基于k8s的7层负载均衡，nginx-ingress也是已addon方式加入k8s集群，以pod的方式运行，多个副本，高可用。
二、Nginx Ingress 一般有三个组件组成：
1）ingress是kubernetes的一个资源对象，用于编写定义规则。
2）反向代理负载均衡器，通常以Service的Port方式运行，接收并按照ingress定义的规则进行转发，通常为nginx，haproxy，traefik等，本文使用nginx。
3）ingress-controller，监听apiserver，获取服务新增，删除等变化，并结合ingress规则动态更新到反向代理负载均衡器上，并重载配置使其生效。

以上三者有机的协调配合起来，就可以完成 Kubernetes 集群服务的暴露。
来看个图例：

Nginx 对后端运行</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2019-12-07&nbsp;&nbsp;
        
        
          <i class="iconfont icon-inbox"></i>
          
            <a href="/categories/K8S">K8S</a>&nbsp;
          &nbsp;
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/Kubernetes">Kubernetes</a>&nbsp;
          
            <a href="/tags/K8S">K8S</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2019/12/06/K8S集群优化之路由转发：使用IPVS替代iptables/">
        <p class="h4 index-header">K8S集群优化之路由转发：使用IPVS替代iptables</p>
        
        
          
        
        <div class="index-excerpt">
          <div class="index-text mb-1">一、为什么要使用IPVS从k8s的1.8版本开始，kube-proxy引入了IPVS模式，IPVS模式与iptables同样基于Netfilter，但是采用的hash表，因此当service数量达到一定规模时，hash查表的速度优势就会显现出来，从而提高service的服务性能。
二、具体步骤2.1、开启内核参数cat &gt;&gt; /etc/sysctl.conf &lt;&lt; EOFnet.ipv4.ip_forward = 1net.bridge.bridge-nf-call-iptables = 1net.bridge.bridge-nf-call-ip6tables = 1EOFsysctl -p
2.2、开启ipvs支持yum -y install ipvsadm  ipset# 临时生效modprobe -- ip_vsmodprobe -- ip_vs_rrmodprobe -- ip_vs_wrrmodprobe -- ip_vs_shmodprobe -- nf_conntrack_ipv4# 永久生效cat &gt; /etc/sysconfig/modu</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2019-12-06&nbsp;&nbsp;
        
        
          <i class="iconfont icon-inbox"></i>
          
            <a href="/categories/K8S">K8S</a>&nbsp;
          &nbsp;
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/Kubernetes">Kubernetes</a>&nbsp;
          
            <a href="/tags/K8S">K8S</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2019/12/05/ansible自动化部署kubernetes-1.16/">
        <p class="h4 index-header">ansible自动化部署kubernetes-1.16</p>
        
        
          
        
        <div class="index-excerpt">
          <div class="index-text mb-1">概述：集群包含coreDNS、cni、nginx-ingress、HA、flanneld
百度网盘链接：https://pan.baidu.com/s/1KYbpshhpTu62DnQwF1LUnQ 提取码：vi5e
一、单master部署[root@k8s-ansible1 ~]# tree ansible-install-k8s-masteransible-install-k8s-master├── add-node.yml├── ansible.cfg├── group_vars│   └── all.yml├── hosts├── multi-master-deploy.yml├── multi-master.jpg├── README.md├── roles│   ├── addons│   │   ├── files│   │   │   ├── coredns.yaml│   │   │   ├── ingress-controller.yaml│   │   │   ├── kube-flannel.yaml│   │   │   └── kubernetes-dash</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2019-12-05&nbsp;&nbsp;
        
        
          <i class="iconfont icon-inbox"></i>
          
            <a href="/categories/K8S">K8S</a>&nbsp;
          &nbsp;
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/Kubernetes">Kubernetes</a>&nbsp;
          
            <a href="/tags/K8S">K8S</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2019/12/01/搭建一个生产级K8S高可用集群（2）/">
        <p class="h4 index-header">搭建一个生产级K8S高可用集群（2）</p>
        
        
          
        
        <div class="index-excerpt">
          <div class="index-text mb-1">写在前面：此次为了贴合线上的真实情况，此次K8S搭建将不会和咱们网路上的一气呵成相媲美，更多的表现在：

最新版K8S_1.16；
完全基于离线模式的二进制HA搭建（政企）《链接：https://pan.baidu.com/s/1aCmiYdfn5gujnyMutVdaVw提取码：m39k》；
全部组件均采用二进制部署（包含Docker）；
逐一摸索每个组件的配置文件，做到线上有故障能清楚的定位到问题；
既然是分布式，本次安装完全基于：
先单Master到双Master高可用；
新Node如何加到集群；



服务器硬件配置推荐：
生产环境K8S平台规划 – 单Master集群
生产环境K8S平台规划 – 多Master集群（HA）
一、服务器规划


角色
IP
组件




k8s-master1
192.168.171.134
kube-apiserver，kube-controller-manager，kube-scheduler，etcd


k8s-master2
192.168.171.135
kube-apiserver，kube-controller-manager，</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2019-12-01&nbsp;&nbsp;
        
        
          <i class="iconfont icon-inbox"></i>
          
            <a href="/categories/K8S">K8S</a>&nbsp;
          &nbsp;
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/Kubernetes">Kubernetes</a>&nbsp;
          
            <a href="/tags/K8S">K8S</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2019/11/26/搭建一个生产级K8S高可用集群（1）/">
        <p class="h4 index-header">搭建一个生产级K8S高可用集群（1）</p>
        
        
          
        
        <div class="index-excerpt">
          <div class="index-text mb-1">不多说了，2019年底再开始~~
一、K8S特性①自我修复在节点故障时重新启动失败的容器，替换和重新部署，保证预期的副本数量；杀死健康检查失败的容器，并且在未准备好之前不会处理客户端的请求，确保服务不中断。
②弹性伸缩使用命令、UI管控或者基于CPU使用情况自动快速扩容和缩容应用程序实例，保证应用业务高峰并发时的高可用性；业务低峰时回收资源，以最小成本运行业务。
③自动部署和回滚K8S采用滚动更新策略更新应用，一次更新一个Pod，而不是同时删除所有Pod，如果更新过程中出现问题，将回滚更改，确保升级不影响业务。
④服务发现和负载均衡K8S为多个容器提供一个统一的访问入口（内部IP地址和一个DNS名称），并且负载均衡关联的所有容器，使得用户无需考虑容器IP问题。
⑤机密和配置管理管理机密数据和应用程序配置，而不需要把敏感数据暴露在镜像里，提高敏感数据安全性。并可以将一些常用的配置存储在K8S中，方便应用程序使用。
⑥存储编排挂载外部存储系统，无论是来自本地存储，公有云（如AWS），还是网路存储（如NFS，ClusterFS，Ceph）都作为集群资源的一部分使用，极大提高存储使用灵活性。
</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2019-11-26&nbsp;&nbsp;
        
        
          <i class="iconfont icon-inbox"></i>
          
            <a href="/categories/K8S">K8S</a>&nbsp;
          &nbsp;
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/Kubernetes">Kubernetes</a>&nbsp;
          
            <a href="/tags/K8S">K8S</a>&nbsp;
          
        
      </div>
    </div>
  </div>

  <div class="row mb-4 mx-auto">
    
    
    <div class="col-12 col-md-8 m-auto">
      <a href="/2019/11/14/Liveness, Readiness与Startup Probes/">
        <p class="h4 index-header">Liveness, Readiness与Startup Probes</p>
        
        
          
        
        <div class="index-excerpt">
          <div class="index-text mb-1">一、探针的种类
livenessProbe：健康状态检查，周期性检查服务是否存活，检查结果失败，将重启容器；

readinessProbe：可用性检查，周期性检查服务是否可用，不可用将从service的endpoints中移除；

startupProbe：启动探针，首次初始化时需要额外启动时间的应用程序，超过设定的启动时间，将被杀死；


kubelet使用活跃度探针知道什么时候重新启动的容器。例如，活动性探针可能会陷入僵局，而应用程序正在运行，但无法取得进展。在这种状态下重新启动容器可以帮助使应用程序尽管存在错误也更可用。
Kubelet使用就绪性探测器来了解何时Container准备开始接受流量。当Pod的所有容器都准备就绪时，即视为准备就绪。此信号的一种用法是控制将哪些Pod用作服务的后端。当Pod尚未就绪时，会将其从服务负载平衡器中删除。
kubelet使用启动探针来了解何时启动Container应用程序。如果配置了这样的探针，它将禁用活动性和就绪性检查，直到成功为止，以确保这些探针不会干扰应用程序的启动。这可用于对启动缓慢的容器进行活动检查，避免它们在启动和运行之前被ku</div>
        </div>
      </a>

      <div>
        
          <i class="iconfont icon-riqi2"></i>&nbsp;2019-11-14&nbsp;&nbsp;
        
        
        
          <i class="iconfont icon-tag"></i>
          
            <a href="/tags/Kubernetes">Kubernetes</a>&nbsp;
          
            <a href="/tags/K8S">K8S</a>&nbsp;
          
        
      </div>
    </div>
  </div>



  <nav aria-label="index posts navigation">
    <span class="pagination pg-blue justify-content-center mt-5" id="pagination">
      <a class="extend prev" rel="prev" href="/"><i class="fas fa-angle-double-left"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><a class="extend next" rel="next" href="/page/3/"><i class="fas fa-angle-double-right"></i></a>
    </span>
  </nav>
  
  <script>
    for (ele of document.getElementById("pagination").getElementsByClassName("page-number")) {
      ele.href += '#board';
    }
  </script>



              </div>
            </div>
          </div>
        </div>
      </div>
    
  </main>

  
    <a class="z-depth-1" id="scroll-top-button" href="#" role="button">
      <i class="fa fa-chevron-up scroll-top-arrow" aria-hidden="true"></i>
    </a>
  

  
    <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel" aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
  

  <footer class="mt-5">
  <div class="text-center py-3">
    <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><b>Hexo</b></a>
    <i class="iconfont icon-love"></i>
    <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"> <b>Fluid</b></a>
    <br>

    
  
    <!-- 不蒜子统计PV -->
    
    &nbsp;<span id="busuanzi_container_site_pv">总访问量 
          <span id="busuanzi_value_site_pv"></span> 次</span>&nbsp;
  
  
    <!-- 不蒜子统计UV -->
    
    &nbsp;<span id="busuanzi_container_site_uv">总访客数 
            <span id="busuanzi_value_site_uv"></span> 人</span>&nbsp;
  
  <br>



    
  <!-- 备案信息 -->
  <a href="http://beian.miit.gov.cn/" target="_blank" rel="nofollow noopener">苏ICP备16041225号-2</a>
  



    <!-- cnzz Analytics icon -->
    

  </div>
</footer>

<!-- SCRIPTS -->
<script src="/lib/jquery/jquery.min.js"></script>
<script src="/lib/popper/popper.min.js"></script>
<script src="/lib/bootstrap/js/bootstrap.min.js"></script>
<script src="/lib/mdbootstrap/js/mdb.min.js"></script>
<script src="/js/main.js"></script>






  <script src="/lib/smooth-scroll/smooth-scroll.min.js"></script>



  <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>


<!-- Plugins -->


  

  

  

  

  <!-- cnzz Analytics -->
  



  <script src="/lib/prettify/prettify.min.js"></script>
  <script>
    $(document).ready(function () {
      $('pre').addClass('prettyprint  ');
      prettyPrint();
    })
  </script>



  <script src="/lib/typed/typed.min.js"></script>
  <script>
    var typed = new Typed('#subtitle', {
      strings: [
        '  ',
        "今日任务： 熬夜 (1/1)&nbsp;",
      ],
      cursorChar: "_",
      typeSpeed: 50,
      loop: false,
    });
    typed.stop();
    $(document).ready(function () {
      $(".typed-cursor").addClass("h2");
      typed.start();
    });
  </script>



  <script src="/lib/anchor/anchor.min.js"></script>
  <script>
    anchors.options = {
      placement: "right",
      visible: "false",
      
    };
    var el = "h1,h2,h3,h4,h5,h6".split(",");
    var res = [];
    for (item of el) {
      res.push(".markdown-body > " + item)
    }
    anchors.add(res.join(", "))
  </script>



  <script src="/js/local-search.js"></script>
  <script>
    var path = "/local-search.xml";
    var inputArea = document.querySelector("#local-search-input");
    inputArea.onclick = function () {
      getSearchFile(path);
      this.onclick = null
    }
  </script>



  <script src="/lib/fancybox/jquery.fancybox.min.js"></script>
  <script>
    $("#post img:not(.no-zoom img, img[no-zoom])").each(
      function () {
        var element = document.createElement("a");
        $(element).attr("data-fancybox", "images");
        $(element).attr("href", $(this).attr("src"));
        $(this).wrap(element);
      }
    );
  </script>





  
  
    <script>
      !function (e, t, a) {
        function r() {
          for (var e = 0; e < s.length; e++) s[e].alpha <= 0 ? (t.body.removeChild(s[e].el), s.splice(e, 1)) : (s[e].y--, s[e].scale += .004, s[e].alpha -= .013, s[e].el.style.cssText = "left:" + s[e].x + "px;top:" + s[e].y + "px;opacity:" + s[e].alpha + ";transform:scale(" + s[e].scale + "," + s[e].scale + ") rotate(45deg);background:" + s[e].color + ";z-index:99999");
          requestAnimationFrame(r)
        }

        function n() {
          var t = "function" == typeof e.onclick && e.onclick;
          e.onclick = function (e) {
            t && t(), o(e)
          }
        }

        function o(e) {
          var a = t.createElement("div");
          a.className = "heart", s.push({
            el: a,
            x: e.clientX - 5,
            y: e.clientY - 5,
            scale: 1,
            alpha: 1,
            color: c()
          }), t.body.appendChild(a)
        }

        function i(e) {
          var a = t.createElement("style");
          a.type = "text/css";
          try {
            a.appendChild(t.createTextNode(e))
          } catch (t) {
            a.styleSheet.cssText = e
          }
          t.getElementsByTagName("head")[0].appendChild(a)
        }

        function c() {
          return "rgb(" + ~~(255 * Math.random()) + "," + ~~(255 * Math.random()) + "," + ~~(255 * Math.random()) + ")"
        }

        var s = [];
        e.requestAnimationFrame = e.requestAnimationFrame || e.webkitRequestAnimationFrame || e.mozRequestAnimationFrame || e.oRequestAnimationFrame || e.msRequestAnimationFrame || function (e) {
          setTimeout(e, 1e3 / 60)
        }, i(".heart{width: 10px;height: 10px;position: fixed;background: #f00;transform: rotate(45deg);-webkit-transform: rotate(45deg);-moz-transform: rotate(45deg);}.heart:after,.heart:before{content: '';width: inherit;height: inherit;background: inherit;border-radius: 50%;-webkit-border-radius: 50%;-moz-border-radius: 50%;position: fixed;}.heart:after{top: -5px;}.heart:before{left: -5px;}"), n(), r()
      }(window, document);
    </script>
  



  <script>(function (i, s, o, g, r, a, m) {
      i['DaoVoiceObject'] = r;
      i[r] = i[r] ||
        function () {
          (i[r].q = i[r].q || []).push(arguments);
        };
      i[r].l = 1 * new Date();
      a = s.createElement(o);
      m = s.getElementsByTagName(o)[0];
      a.async = 1;
      a.src = g;
      a.charset = 'utf-8';
      m.parentNode.insertBefore(a, m);
    })(window, document, 'script', ('https:' === document.location.protocol ? 'https:' : 'http:') + "//widget.daovoice.io/widget/f304979b.js", 'daovoice');
    daovoice('init', {
      app_id: "f304979b",
    });
    daovoice('update');
  </script>





</body>
</html>
